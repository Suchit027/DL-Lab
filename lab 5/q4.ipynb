{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "train = datasets.MNIST('.', train= True, download= True, transform= transforms)\n",
    "test = datasets.MNIST('.', train= False, download= True, transform=transforms)\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle= True)\n",
    "test_loader = DataLoader(test, batch_size= 64, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2),\n",
    "                                 nn.Conv2d(32, 64, kernel_size=3), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride=2),\n",
    "                                 nn.Conv2d(64, 32, kernel_size= 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2))\n",
    "        self.classify_head = nn.Sequential(nn.Linear(32, 20, bias= True),\n",
    "                                           nn.Linear(20, 10, bias= True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classify_head(self.net(x).reshape(-1, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0, loss = 2151.112156867981\n",
      "Epoch - 1, loss = 2131.0279171466827\n",
      "Epoch - 2, loss = 2099.186537027359\n",
      "Epoch - 3, loss = 2033.7613525390625\n",
      "Epoch - 4, loss = 1874.346396803856\n",
      "Epoch - 5, loss = 1557.3057669401169\n",
      "Epoch - 6, loss = 1191.4873133897781\n",
      "Epoch - 7, loss = 865.344142138958\n",
      "Epoch - 8, loss = 629.1617791950703\n",
      "Epoch - 9, loss = 493.97765186429024\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch - {epoch}, loss = {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 904    0    4    0    4   16   49    1    1    1]\n",
      " [   0 1112    3    1    0    3    2    3   11    0]\n",
      " [   1    9  854   16    7    9   13   36   76   11]\n",
      " [   0    1   17  932    0   15    0   14   18   13]\n",
      " [   2    4    0    0  870    4   39    4    9   50]\n",
      " [   6    9    2   25    3  760   29    5   26   27]\n",
      " [  50    7    3    0   48   17  824    0    8    1]\n",
      " [   4    5   56   31   14    3    1  863   15   36]\n",
      " [   0   10   26   28    5   56   14   15  749   71]\n",
      " [   7    5    3   17   33   26    8   34   34  842]]\n",
      "38150\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        output = model(input)\n",
    "        val, index = torch.max(output, 1)\n",
    "        all_preds.extend(index)\n",
    "        all_labels.extend(target)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
